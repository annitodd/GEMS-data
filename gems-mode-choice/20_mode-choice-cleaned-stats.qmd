---
title: "Summary Stats"
format: gfm
execute:
  warning: false
---

html: code-fold: true df-print: paged

## Description and Overview

This code summarizes the dataset that is a result of this script: 10_mode-choice-cleaning

GitHub: This .Rmd code (possibly qmd if I have to change it with the new update to R Studio) is synced to Github, and when this code is knit, it's also synced to GitHub, as a .md file, which makes the knitted code easy to read (kind of like python code.) Currently in a FORK: <https://github.com/annitodd/GEMS-data/blob/main/gems-mode-choice>

### Latest Updates

####DEC 6: the next step is to go back to the 10\_ code, and add income

#### Dec 14: next step
Is to create the dataset that replicates the one i've been talking to anna about in that excel sheet
But FIRST make a mandatory vs non-mandatory

another to-do is ALSO use the raw raw data in the folder that I found

## Setup

### libraries

```{r}
library(arrow)
library(tidyverse)
library(readxl)
library(rstudioapi)
library(scales)
library(writexl)
library(sjmisc)
library(fmlogit)
library(tidyverse) # use this last

```

### file path directories

```{r}
# get current root directory of the user's Github repo
root <- getwd() # Saves current WD 
#while ((basename(root) != "GEMS-data")) {
#  root <- dirname(root)
#} # Sets root equal to the location of the Github repo
#source(file.path(root, "paths.R")) # Runs paths.R file found in users Github repo
```

```{r}
data_path <- 'C:/FHWA/For FHWA folks/Mode_choice_estimation/Data'
data_results <- 'C:/FHWA_R2/mode_choice_estimation/data'
```

## Data: open and slim down

### read in big dataset

full merged dataset

```{r}
df_temp <- read_parquet(file.path(data_results, "10-mode-choice-cleaning_output-full-merged.parquet"))
names(df_temp)
```
### Summarize

Recall that they don't equally merge, as we saw before (hhct has more households on file). Anna notes that this is likely because lots of households took the survey but only some of them filled out the trips diary part.

```{r}
df_temp |>
  count(rawdatafrom_trippub_ATB,rawdatafrom_tripct_ATB,rawdatafrom_hhct_ATB)
df_temp <- ungroup(df_temp)
```

The number of **observations** in the dataset (these should give the same answer):

```{r}
df_temp |> summarise(n())
df_temp |> summarise(n_distinct(HOUSEID,PERSONID,TDTRPNUM))
```

number of **people** in the dataset:

```{r}
df_temp |> summarise(n_distinct(HOUSEID,PERSONID))
```

number of **people** in the dataset **with trips** (there are FEWER people with trips than there are total people:

```{r}
df_temp |> 
  filter(rawdatafrom_trippub_ATB==1,rawdatafrom_tripct_ATB==1,rawdatafrom_hhct_ATB==1) |> summarise(n_distinct(HOUSEID,PERSONID))
```

The number of **households** in the dataset:

```{r}
df_temp |> summarise(n_distinct(HOUSEID))
```

The number of **households** in the dataset **with trips**:

```{r}
df_temp |> 
  filter(rawdatafrom_trippub_ATB==1,rawdatafrom_tripct_ATB==1,rawdatafrom_hhct_ATB==1) |> summarise(n_distinct(HOUSEID))
```

#### Missing observations


```{r}
summary <- df_temp |>
    group_by(mode_ATB) |>
  summarise(countN = n() ,
            Nmissing = sum(is.na(mode_ATB)),
    .groups = "drop") |> 
  arrange(-countN)   
summary
```


For the **bin class** It looks like the missing values are from the non-trip survey part, but ALSO, many distance bins that are missing (656 of them)

```{r}
df_temp |> 
  count(distance_bin_class_ATB,rawdatafrom_tripct_ATB,rawdatafrom_hhct_ATB)

```

Now **missings for all of the important vars** , the important ones end with _ATB

```{r}
summary_table <- df_temp |> 
  select(contains("_ATB")) |> 
  summarise(
          countN = n(),
          across(.cols=everything(), ~sum(is.na(.x)),.names = "{.col}_Missing"),
            across(where(is.factor ),~n_distinct(.x),.names = "{.col}_Ndis"),
            , .groups = "drop") |> 
  arrange(countN) 
summary_table %>% sjmisc::rotate_df(rn="N distinct")
```

another way to look at some missings:
```{r}
df_temp |> 
  count(user_class_ATB,rawdatafrom_tripct_ATB,rawdatafrom_hhct_ATB)
```

What if we look only at the ones that are from the trip data:
```{r}
summary_table <- df_temp |> 
  select(contains("_ATB")) |> 
  group_by(rawdatafrom_trippub_ATB,rawdatafrom_tripct_ATB,rawdatafrom_hhct_ATB) |> 
  summarise(
          countN = n(),
          across(.cols=everything(), ~sum(is.na(.x)),.names = "{.col}_Missing"),
            across(where(is.factor ),~n_distinct(.x),.names = "{.col}_Ndis"),
            , .groups = "drop") |> 
  arrange(countN) 
summary_table
summary_table %>% sjmisc::rotate_df(rn="V2 is obs with trips")
```



```{r}


df_trips_only <- df_temp |> 
  filter(rawdatafrom_trippub_ATB==1,rawdatafrom_tripct_ATB==1,rawdatafrom_hhct_ATB==1)

df_trips_only |> 
  count(rawdatafrom_trippub_ATB,rawdatafrom_tripct_ATB,rawdatafrom_hhct_ATB)
df_trips_only <- ungroup(df_trips_only)
```

### list of variables and descriptions

```{r}
names(df_trips_only)
```

This is the data dictionary from NHTS:

```{r}
dictionary_v1_2 <- read_csv("dictionary_v1_2.csv") %>% 
  relocate ("Label","Name")
dictionary_v1_2 
```

## Smaller dataset

### REMOVE variables

choose only some vars: keep all of the ones that we made. These all end in "\_ATB"

```{r}
names(df_trips_only)
```


```{r}
df_trips_only_small <- df_trips_only |> 
  select(contains("_ATB")) %>% 
  select(-contains("rawdatafrom"))
df_trips_only_small
```


### save with fewer variables AND only trips
This keeps only some variables

```{r}
df_trips_only_small <- df_trips_only |> 
  select(contains("_ATB")) %>% 
  select(-contains("rawdatafrom"))

write_parquet(df_trips_only_small,  file.path(data_results, "10-mode-choice-cleaning_output-merged-onlytrips-fewvars.parquet"))
write_rds(df_trips_only_small,  file.path(data_results, "10-mode-choice-cleaning_output-merged-onlytrips-fewvars.rds"))
write_csv(df_trips_only_small,  file.path(data_results, "10-mode-choice-cleaning_output-merged-onlytrips-fewvars.csv"))
```

#### Number of distinct groups in each variable

```{r}
summary <- df_trips_only_small |>
  summarise("Number Obs" = n(),
            across(contains("_ATB"),~n_distinct(.x),.names = "{.col} distinct"),
    .groups = "drop")
summary
summary %>% sjmisc::rotate_df(rn="N distinct")
```

```{r}
names(df_trips_only_small)
```

### Summarise and Examine:

#### the key vars

```{r}
names(df_trips_only_small)
```


##### the distinct values

```{r}
df_trips_only_small %>% 
  distinct(origin_geoXmicrotype_ATB) 
```

```{r}
df_trips_only_small %>% 
  distinct(dest_geoXmicrotype_ATB) 
```

```{r}
df_trips_only_small %>% 
  distinct(hh_geoXmicrotype_ATB) 
```

```{r}
df_trips_only_small %>% 
  distinct(start_time_bin_ATB) 
```

```{r}
df_trips_only_small %>% 
  distinct(trip_purpose_ATB) 
```

#### how many combinatorials

distinct mode X trip purpose

```{r}
summary <- df_trips_only_small |>
  group_by(mode_ATB,trip_purpose_ATB) %>% 
  summarise("Number Obs" = n(),
            across(contains("_ATB"),~n_distinct(.x),.names = "{.col} distinct"),
    .groups = "drop")
summary
summary %>% sjmisc::rotate_df(rn="N distinct")
```

##### distinct origin destination

```{r}
df_trips_only_small %>% 
  count(origin_geoXmicrotype_ATB,dest_geoXmicrotype_ATB) %>% 
  pivot_wider(names_from = dest_geoXmicrotype_ATB,values_from = n)
```

###### 12/7 do only micro types not geo types

```{r}

ggplot() +
  geom_count(data=df_trips_only_small,
             mapping=aes(x = origin_microtypeXgeotype_ATB, y = dest_microtypeXgeotype_ATB)) +
  scale_size_area(max_size = 10)

```

```{r}

ggplot() +
  geom_count(data=df_trips_only_small,
             mapping=aes(x = origin_geoXmicrotype_ATB, y = dest_geoXmicrotype_ATB)) +
  scale_size_area(max_size = 10)

```


```{r}
df_trips_only_small %>% 
  count(origin_microtypeXgeotype_ATB,dest_microtypeXgeotype_ATB) 
df_trips_only_small %>% 
  count(origin_geoXmicrotype_ATB,dest_geoXmicrotype_ATB) %>% 
  filter(n<100) %>% 
  ggplot( aes(x = n)) +
  geom_histogram(binwidth = 5)
```


```{r}
temp_count <- df_trips_only_small %>% 
  count(origin_geoXmicrotype_ATB,dest_geoXmicrotype_ATB)

ggplot() +
  geom_tile(data=temp_count,
            mapping=aes(x = origin_geoXmicrotype_ATB, 
                        y = dest_geoXmicrotype_ATB,
                        fill = log(n)))
```

```{r}
ggplot() +
  geom_tile(data=temp_count,
            mapping=aes(x = origin_geoXmicrotype_ATB, 
                        y = dest_geoXmicrotype_ATB,
                        fill = log(n))) +
  geom_point(data=temp_count %>% filter(n<8),
            mapping=aes(x = origin_geoXmicrotype_ATB, 
                        y = dest_geoXmicrotype_ATB,
                        size = -n),
            color = "red",
            alpha = .5) 
  
```

```{r}
#| warning: false
ggplot(df_trips_only_small, 
       aes(x = origin_geoXmicrotype_ATB, 
           y = dest_geoXmicrotype_ATB,
           color = start_time_bin_ATB,
           shape = trip_purpose_ATB)) +
  geom_count()
```

```{r}
summary <- df_trips_only_small |>
  group_by(origin_geoXmicrotype_ATB) %>% 
  summarise("Number Obs" = n(),
            across(contains("_ATB"),~n_distinct(.x),.names = "{.col} distinct"),
    .groups = "drop")
36*36
summary
summary %>% sjmisc::rotate_df(rn="N distinct")
```

```{r}
summary <- df_trips_only_small |>
  group_by(origin_geoXmicrotype_ATB,dest_geoXmicrotype_ATB) %>% 
  summarise("Number Obs" = n(),
            across(contains("_ATB"),~n_distinct(.x),.names = "{.col} distinct"),
    .groups = "drop")
36*36
summary
summary %>% sjmisc::rotate_df(rn="N distinct")
```

## Data:

## Data: make analysis dataset (wider)

This is based on notes from here: <https://docs.google.com/spreadsheets/d/1ERafo_dtfzE6o0_MMA9KZGOPj6Jkycqd/edit?usp=sharing&ouid=109372603671818325634&rtpof=true&sd=true>

make wider dataset to examine further:

then use the smaller to make wider dataset. This is to make the modes go across rather than down

```{r}
df_trips_only_small <- df_trips_only_small |>
  mutate(onePerObs = 1)
```

```{r}
df_trips_only_small_wide <- df_trips_only_small  |>
  group_by(origin_geoXmicrotype_ATB,dest_geoXmicrotype_ATB) %>% 
  summarise("Number Obs" = n(),
            across(contains("_ATB"),~n_distinct(.x),.names = "{.col}"),
    .groups = "drop")
df_trips_only_small_wide
```

#### How many have all 7 modes?

```{r}
df_trips_only_small_wide  %>% 
  pivot_wider(
    names_from = mode_ATB,
    values_from = "Number Obs",
    values_fn = sum
  )
df_trips_only_small_wide

# df_trips_only_small %>% 
#   count(origin_geoXmicrotype_ATB,dest_geoXmicrotype_ATB) %>% 
#   pivot_wider(names_from = dest_geoXmicrotype_ATB,values_from = n)
```

### make county level dataset

```{r}
# df_county_origin <- df_trips_only_small |>
#   group_by(ORIG_ST,ORIG_CNTY) |>
#   summarise(Ntrips = n(),
#             across(contains("mode_ATB"),~n_distinct(.x),.names = "{.col}_Ndis"),
#     .groups = "drop")
# df_county_origin
```

### make microXgeotype level dataset

```{r}
df_microXgeotype <- df_trips_only_small |>
  group_by(origin_geoXmicrotype_ATB,dest_geoXmicrotype_ATB) |>
  summarise(Ntrips = n(),
            across(contains("_ATB"),~n_distinct(.x),.names = "{.col}_Ndis"),
    .groups = "drop")
df_microXgeotype
```

## START HERE DEC 14!!

## This is where put the modes wider
After count, then next step is to get the proportion
```{r}
names(df_trips_only_small)

```

### Collapse by type unit etc  

#### CHANGE to summary instead of  through count)

```{r}
df_collapsed <- df_trips_only_small |>
    count(origin_microXgeo2types_ATB,dest_microXgeo2types_ATB,
          trip_purpose_small_ATB,start_time_bin_ATB,user_class_ATB,distance_bin_class_ATB,
          mode_ATB)
df_collapsed
```
#### histogram

```{r}
df_collapsed |> 
  filter(n<20) |>  
  ggplot( aes(x = n)) +
  geom_histogram(binwidth = 1)
```

### Then widen
```{r}
df_collapsed_wide <- df_collapsed  %>% 
   pivot_wider(
    names_from = mode_ATB,
    values_from = n
  )
df_collapsed_wide

```
### save widened

```{r}
df_trips_only_small <- df_trips_only |> 
  select(contains("_ATB")) %>% 
  select(-contains("rawdatafrom"))

write_parquet(df_collapsed_wide,  file.path(data_results, "10-mode-choice-cleaning_output-merged-onlytrips-fewvars-wide.parquet"))
write_rds(df_collapsed_wide,  file.path(data_results, "10-mode-choice-cleaning_output-merged-onlytrips-fewvars-wide.rds"))
write_csv(df_collapsed_wide,  file.path(data_results, "10-mode-choice-cleaning_output-merged-onlytrips-fewvars-wide.csv"))
```
## histograms


#### histogram mode stacked
```{r}
df_collapsed |> 
  filter(n<50) |>  
  ggplot( aes(x = n, fill = mode_ATB)) +
  geom_histogram(binwidth = 1)
```
#### histogram mode faceted
```{r}
df_collapsed |> 
  filter(n<10) |>  
  ggplot( aes(x = n)) +
  geom_histogram(binwidth = 1) +
  facet_wrap(vars(mode_ATB),nrow=2)
```

#### histogram mode lines
```{r}
df_collapsed |> 
  filter(n<50) |>  
  ggplot( aes(x = n, colour = mode_ATB)) +
  geom_freqpoly(binwidth = 1)
```

#### look at the bins graph
```{r}
#| warning: false
ggplot(df_trips_only_small, 
       aes(x = origin_microXgeo2types_ATB, 
           y = dest_microXgeo2types_ATB)) +
  geom_count()
```

```{r}
#| warning: false
ggplot(df_trips_only_small, 
       aes(x = origin_microXgeo2types_ATB, 
           y = dest_microXgeo2types_ATB,
           color = start_time_bin_ATB,
           shape = trip_purpose_small_ATB)) +
  geom_count()
```
```{r}
#| warning: false
ggplot(df_trips_only_small, 
       aes(x = origin_microXgeo2types_ATB, 
           y = user_class_ATB,
           color = start_time_bin_ATB,
           shape = trip_purpose_small_ATB,
           fill = distance_bin_class_ATB)) +
  geom_count()
```
```{r}
#| warning: false
ggplot(df_trips_only_small, 
       aes(x = origin_microXgeo2types_ATB, 
           y = user_class_ATB)) +
  geom_count()
```
```{r}
#| warning: false
ggplot(df_trips_only_small, 
       aes(x = origin_microXgeo2types_ATB, 
           y = distance_bin_class_ATB)) +
  geom_count()
```

### END 12/15

#### NEXT 12/15
Make a new histogram

#### WHY? doesn't this work without count?
```{r}

df_trips_only_small %>% 
  count(origin_microXgeo2types_ATB,dest_microXgeo2types_ATB,
          trip_purpose_small_ATB,start_time_bin_ATB,user_class_ATB,distance_bin_class_ATB,
          mode_ATB) %>% 
  filter(n<20) %>% 
  ggplot( aes(x = n)) +
  geom_histogram(binwidth = 1)
```

```{r}

df_collapsed <- df_trips_only_small |>
    count(origin_microXgeo2types_ATB,dest_microXgeo2types_ATB,
          trip_purpose_small_ATB,start_time_bin_ATB,user_class_ATB,distance_bin_class_ATB,
          mode_ATB)
df_collapsed |> 
  count(origin_geoXmicrotype_ATB,dest_geoXmicrotype_ATB) %>% 
  filter(n<100) %>% 
  ggplot( aes(x = n)) +
  geom_histogram(binwidth = 5)
```


### Wide microgeo by mode to get fractions (first get the sum)

```{r}
df_microXgeotype_wide <- df_trips_only_small |>
    count(origin_geoXmicrotype_ATB,dest_geoXmicrotype_ATB,
          trip_purpose_ATB,start_time_bin_ATB,
          mode_ATB) %>% 
   pivot_wider(
    names_from = mode_ATB,
    values_from = n
  )
df_microXgeotype_wide
```

### new dataset

-   county
-   user class (income variation) use xiaodan's
-   trip purpose -- which may or may not. Mandatory versus non-mandatory. Work and School
-   trip distance bin
-   departure time bin

Micro-geotype -- merge this into the dataset, and then use micro type. Break up by micro geo Replace county by microtype. There are 6 microtypes. Use Origin and destination microtypes -- could do that, then there would be

Need to ask Xiaodan to how to merge microtype and geo type IDs to FIPS blocks.

Then Combinatorials of

## Summary stats by coumty

### basic

how many trips in each state

```{r}
summary_table <- df_trips_only |> 
  group_by(ORIG_ST) |>
  summarise(   
    Ntrips = n(),
    .groups = "drop")
summary_table
```

how many trips for each mode

```{r}
summary_table <- df_trips_only |> 
  group_by(mode_ATB) |>
  summarise(   
    Ntrips = n(),
    .groups = "drop") |>
  arrange(-Ntrips)   
summary_table
```

### by county

how many trips in each county

```{r}
ggplot(df_county_origin,aes(x=Ntrips)) +
  geom_histogram(binwidth=1) +
  coord_cartesian(xlim = c(0, 50))
```

### by mode type by

```{r}
# ggplot(df_county_origin,aes(x=mode_Ndis)) +
#   geom_histogram(binwidth=1) 
# #  coord_cartesian(xlim = c(0, 50))
```

### by purpose

```{r}
df_county_origin <- df_trips_only_small |>
  group_by(mode_ATB,trip_purpose_ATB) |>
  summarise(Ntrips = n(),
            #across(contains("mode_ATB"),~n_distinct(.x),.names = "{.col}_Ndis"),
    .groups = "drop")
#df_county_origin
df_county_origin
```

```         
      across(where(is.numeric),~mean(.x),.names = "{.col}_avg"),
        across(where(is.factor ),~n_distinct(.x),.names = "{.col}_Ndis"),
```

## Make new proportional dataset

### by microXgeotype

```{r}
# ggplot(df_county_origin,aes(x=Ntrips)) +
#   geom_histogram(binwidth=1) +
#   coord_cartesian(xlim = c(0, 50))
```

## fractional split logit

### methodology

The R package is here, I think it's mostly based on the stata package: https://github.com/f1kidd/fmlogit

It looks like there is no need to include information about how the proportions within each observation were obtained, like how many people or whatever were used to make the proportions, see this from the seminal paper:

Papke, Leslie E., and Jeffrey M. Wooldridge. "Econometric Methods for Fractional Response Variables With an Application to 401 (K) Plan Participation Rates." *Journal of Applied Econometrics*, vol. 11, no. 6, 1996, pp. 619--32. *JSTOR*, http://www.jstor.org/stable/2285155. Accessed 29 Nov. 2023.

![](images/fractional_split_woolridge_2.png){width="465"}

This is an [example](https://www.sciencedirect.com/science/article/abs/pii/S0001457517304049) of a fractional split logit using the fraction of crashes in each TAZ as the y var, and the x vars are descriptors of the TAZ also in proportions. Lee J, Yasmin S, Eluru N, Abdel-Aty M, Cai Q. Analysis of crash proportion by vehicle type at traffic analysis zone level: A mixed fractional split multinomial logit modeling approach with spatial effects. Accid Anal Prev. 2018 Feb;111:12-22. doi: 10.1016/j.aap.2017.11.017. Epub 2017 Nov 20. PMID: 29161538.
