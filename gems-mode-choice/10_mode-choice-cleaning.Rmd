---
date: "Annika created this code doc on 10/21/2023. Last compiled on `r Sys.Date()`"
output:
  github_document:
    df_print: kable
    toc: TRUE
    toc_depth: 1
---

# Description

This code opens raw datasets from NHTS data in 2017, cleans them, possibly merges them, gives super basic summary tables of new stats that are a result of the new vars, and then saves as new datasets. Another code will then use the cleaned dataset from here to make more fancy summary stats.

Data Dictionary: I'm taking the results from this code, and also putting it into the GEMS master data dictionary. They are in NEW TABs including "clean_mode_choice_data_ATB" and other tabs: <https://docs.google.com/spreadsheets/d/1RVxqALDAE1u4SC569Cq373_fafaE1nZiZBJJMiRTYu8/edit?usp=sharing>

GitHub: This .Rmd code (possibly qmd if I have to change it with the new update to R Studio) is synced to Github, and when this code is knit, it's also synced to GitHub, as a .md file, which makes the knitted code easy to read (kind of like python code.) Currently in a FORK: <https://github.com/annitodd/GEMS-data/blob/main/gems-mode-choice/10_mode-choice-cleaning.md>

# Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE) 
```

## libraries

```{r}
rm(list=ls()) # Clear RStudio environment
cat("\014") # Clear console
library(tidyverse)
library(readxl)
library(rstudioapi)
library(scales)
library(writexl)
```

## file path directories

```{r}
# get current root directory of the user's Github repo
root <- getwd() # Saves current WD 
while ((basename(root) != "GEMS-data")) {
  root <- dirname(root)
} # Sets root equal to the location of the Github repo
source(file.path(root, "paths.R")) # Runs paths.R file found in users Github repo
```

```{r}
data_path <- 'C:/FHWA/For FHWA folks/Mode_choice_estimation/Data'
```

# DATA - Open and Clean

## Raw data

These data sets are from the NHST 2017 survey. Documentation is [here](https://nhts.ornl.gov/documentation), with useful [user's guide](https://nhts.ornl.gov/assets/NHTS2017_UsersGuide_04232019_1.pdf), and [codebook](https://nhts.ornl.gov/assets/codebook_v1.2.pdf), and very simple [data dictionary](https://nhts.ornl.gov/assets/dictionary_v1_2.xlsx) that is also saved in Github here.

Data file structure screen shot:

![](pngs/NHST_data_file_structure.png){width="680"}

-   trippub: each row is household-person-trip, without geo IDs, with lots of descriptions of the trips. It's public dataset.
-   tripsct: each row is a household-person-trip, with only geo IDs for *each* trip, like, trip origin geoID and trip destination geoID. The geo IDs are: 2 didget state code, county code, and 6 didget tract code.
-   hhct.csv: each row is a household, with a geo ID for the household.

## Dataset: Person-Trips (trippub)

This has all of the trip information for every trip a household took in the survey, each row is a trip for each person that answered the survey

```{r load, cache=TRUE}
trippub <- read_csv(file=file.path(data_path, 'trippub.csv'))
names(trippub)
saveRDS(trippub, "df_trips.rds")
rm(trippub)
```

```{r}
df_trips <- readRDS("df_trips.rds")
View(df_trips)
names(df_trips)
```

### define modes

Uses TRPTRANS from NHTS

First I'm going to create smaller bins of modes because there are too many, there are like 17 or more The definitions are here: GEMS master data dictionary, in the clean_mode_choice_data tab: <https://docs.google.com/spreadsheets/d/1RVxqALDAE1u4SC569Cq373_fafaE1nZiZBJJMiRTYu8/edit#gid=81250909>

![](pngs/TRPTRANS_dictionary.png)

```{r}
df_trips <- df_trips  %>%
  mutate(mode = 
      case_when(TRPTRANS %in% c("01") ~ 'walk',
                TRPTRANS %in% c("02") ~ 'bike',
                TRPTRANS %in% c(10,11,12,13,14) ~ 'bus', 
                TRPTRANS %in% c(15, 16)~ 'rail',
                TRPTRANS %in% c(17) ~ 'taxi',
      # CONTESTING:
                  TRPTRANS %in% c("03","04","05","06",          "09","18") ~ 'hv', 
                # TRPTRANS %in% c("03","04","05","06",     "08") ~ 'personal vehicle', # PROPOSED
                # TRPTRANS %in% c(18) ~ 'rental', # PROPOSED
                  TRPTRANS %in% c(                    "07","08") ~ 'scooter', 
                # 09 is RV (motor home, ATV, snowmobile)
                # 18 is rental car
                # 08 is motorcycle / moped
                # 07 is golf cart / segway
                # TRPTRANS %in% c(19) ~ 'something else', # PROPOSED
                TRUE ~ "other")
      )


summary <- df_trips |>
    group_by(TRPTRANS, mode) |>
  summarise(countN = n() ,
            Nmissing = sum(is.na(mode)),
    .groups = "drop") |> 
  arrange(TRPTRANS)   
summary
```

```{r}
summary <- df_trips |>
    group_by(mode) |>
  summarise(countN = n() ,
            Nmissing = sum(is.na(mode)),
    .groups = "drop") |> 
  arrange(-countN)   
summary
```

### define trip purpose

trip_purpose generated from NHTS field 'whytrp1s' ![](pngs/WHYTRP1S_dictionary.png)

```{r}
df_trips <- df_trips  %>%
  mutate(trip_purpose = 
      case_when(WHYTRP1S %in% c("01") ~ 'home',
                WHYTRP1S %in% c("10") ~ 'work',
                WHYTRP1S %in% c("20") ~ 'school',
                WHYTRP1S %in% c("30") ~ 'medical',
                WHYTRP1S %in% c("40") ~ 'shopping',
                WHYTRP1S %in% c("50") ~ 'social',
                WHYTRP1S %in% c("70") ~ 'transp_someone',
                WHYTRP1S %in% c("80") ~ 'meals',
                TRUE ~ "other")
      )
summary <- df_trips |>
    group_by(WHYTRP1S, trip_purpose) |>
  summarise(countN = n() ,
            Nmissing = sum(is.na(mode)),
    .groups = "drop") |> 
  arrange(WHYTRP1S)   
summary
```

### define time bins

trip_purpose generated from NHTS field 'STRTTIME' ![](pngs/STRTTIME_dictionary.png)

```{r}
# convert to numeric
df_trips <- df_trips  %>%
  mutate(STRTTIME_num = as.numeric(STRTTIME))
```

```{r}
df_trips <- df_trips  %>%
  mutate(start_time_bin = 
      case_when(STRTTIME_num <=  600 ~ 'morning_rush',
                STRTTIME_num >= 1600 ~ 'evening_rush',
                is.na(STRTTIME_num)  ~ 'missing time',
                TRUE ~ "other_time")
      )
summary <- df_trips |>
    group_by(start_time_bin) |>
  summarise(countN = n() ,
            "Min start time" = min(STRTTIME_num),
            "Max start time" = max(STRTTIME_num),
            Nmissing = sum(is.na(mode)),
    .groups = "drop") |> 
  arrange(start_time_bin)   
summary
```

## Dataset - tripsct: County-Tract Crosswalk

Read in tripsct because it has the county fips codes and census tract to crosswalk

## Dataset - hhct.csv: Household GEOIDs

```{r}
# Houshold GEOIDs?


#df <- read.csv(file = file.path(datadir, "hhct.csv" ))  # household, trip ct.csv -- resticted 

#


```

```{r}
#hhpub -- # this has the household information , demographics, location of household, info from survey
  
  
# PRIVATE data, maps household to trips
#location <- read.csv(file = file.path(datadir, "hhct.csv" ))  # household, trip ct.csv -- resticted data -- only has household location -- links

#df <- tripct.csv # raw trip with od  -- only has tract
# trip path with distance
```

```{r}
1 + 1
knitr::knit_exit()
```

#--- \# END \# \# END \# \*\*\* Notes \*\*\*

# Next Steps

# define distance bins

in the "transition_matrix" tab of the GEMS Master Data dictionary sheet DistanceBinID "Trip distance bin defined as following: • bin1 - distance between 0 and 1 mile • bin2 - distance between 1 and 2 miles • bin3 - distance between 2 and 4 miles • bin4 - distance between 4 and 8 miles • bin5 - distance between 8 and 15 miles • bin6 - distance between 15 and 20 miles • bin7 - distance between 20 and 35 miles • bin8 - distance above 35 miles" \### Note is this inclusive? Check at some point

```{r}

```

## Overview & background

Are there enough counties where there are enough trips within them broken down into heterogeneity that we want to estimate the coefs

enough counties with enough trips for each mode --\> that's what we need

then want to divide by heterogeneous groups.

Next to get heads around: Do we need number of or proportion for each section for each to do the proportional mnl thing Also do we need to weight it?

Goal: how should we collapse the data

## clean data enough that we can get a lots of different histograms

```{r}

```

## Histogram of trip counts by county. Each county will have a number of trips that's within the county

------------------------------------------------------------------------

------------------------------------------------------------------------

-   

```{r}

```

## Histogram of trip counts by mode by county

```{r}

```

## Also pull in the micro geotype indicators

i'll need to ask Xiaodan where the cross walk is between census-tract and microgeotypes

```{r}

```

## TEMPO -- look at how they did it

Use nhts does county level does fractional split logit? they have bins of income levels how did they decide to use their bins? Were they defining the bins <https://www.nrel.gov/transportation/tempo-model.html>

Note: keep all new vars etc, new definitions, at the beginning or in a separate code

## Future next step

### doing a mnl fractional, even if not totally decided on how to make one unit of obs

filter raw trip in the NHTS by origin county tripct is census tract -- last 4 didgets or something is county number of trips by county by mode

-   After that then \*

*User Classes* another need to have definitions of user classes income, age, vehicle ownership -- do we want to keep that definition? Use this to look at definitions -- but don't merge with it bc maybe it excluded some trips: nhts_user_classes_inc_veh_sr.csv 264234 C:\FHWA\For FHWA folks\CleanData\NHTS Xiaodan

*Time Classes* there's a definition somewhere

*Distance Class* Can use this to see what the different classes are -- but these merge with geo types not with census TransitionMatrix-100m.csv 31919 C:\FHWA\For FHWA folks\CleanData Xiaodan

```{r}


  

#df <- load("C:/FHWA_R2/This is from before/Mode_choice_estimation/Data/ModeChoice_Tour_A.Rdata")
```

# train distance data merged to trip locations.

load(file= file.path(datadir,'NHTS_tract_origin_train_dist_transgeo.RData'))

# NOTE: "ct" is restricted, only data for us, like hhct

# "pub" public data

# "perwgt" is also public

# Step 1. Tripspub, maybe merge to ct. Need to merge to county. Take the

# raw trips, have the county / fips codes, then look at how many trips by county

# do we have per trips

# tract IDs, then the microgeotypes -- crosswalk of tract to geotype

This is from before I talked to Anna and Xiaodan:

```{r}
df <- load("C:/FHWA_R2/This is from before/Mode_choice_estimation/Data/ModeChoice_Tour_A.Rdata")
  # readr
("C:/FHWA/For FHWA folks/Mode_choice_estimation/Data/ModeChoice_Tour_A.Rdata")
  
# df_ProBiz_survey_employees <- read_csv(paste0(box, probiz_path))
```

```{r}
df <- od.tr.purpose2 
rm(od.tr.purpose2)
df_mode <- TravelMode
rm(TravelMode)
```

# Summary Stats

```{r}
summary <- df |> 
  group_by(TDTRPNUM) |>
  summarise(count = n())
summary

summary <- df |> 
  group_by(o_geotype) |>
  summarise(count = n())
summary

summary <- df |> 
  group_by(o_microtype) |>
  summarise(count = n())
summary

summary <- df |> 
  group_by(d_geotype) |>
  summarise(count = n())
summary

summary <- df |> 
  group_by(d_microtype) |>
  summarise(count = n())
summary

summary <- df |> 
  group_by(whytrp1s) |>
  summarise(count = n())
summary



```

```{r}
summary <- df_mode |> 
  group_by(mode) |>
  summarise(count = n())
summary
summary <- df_mode |> 
  group_by(mode) |>
  summarise(
    countN = n(),
    across(where(is.numeric),~mean(.x),.names = "{.col}_avg"),
    across(where(is.factor ),~n_distinct(.x),.names = "{.col}_Ndis"))
summary

summary <- df_mode |> 
  group_by(trip_purpose) |>
  summarise(count = n())
summary

summary_modeXpurpose <- df_mode |> 
  group_by(mode, trip_purpose) |>
  summarise(count = n())
summary

summary <- df_mode |> 
  group_by(hometract) |>
  summarise(count = n())
summary

```

```{r}
hist_temp <- 
```

```{r summary}
summary  <-   df_temp |> 
  group_by(lever_position_fleetsize,
           originalDataset,
           lever_position_price) |> 
  summarise(
          across(where(is.numeric),~mean(.x),.names = "{.col}_avg"),
          countN = n(),
          across(.cols=everything(), ~mean(is.na(.x)),.names = "{.col}_Missing"),
          
            PCTwaittimeIs0 = mean(waitTime<0.000001),
            across(where(is.factor ),~n_distinct(.x),.names = "{.col}_Ndis"),
            
            , .groups = "drop") |> 
  arrange(countN) 
problems <- problems |> 
  arrange(lever_position_price, lever_position_fleetsize)
problems <- problems |> 
  relocate(lever_position_price, lever_position_fleetsize,
            contains("wait"),
           contains("duration")
  )
# |> 
  # filter(lever_position_fleetsize==1 & lever_position_price==1)
readr::write_csv(problems,file = paste0(data_dir_on_this_machine,
                             "ReadyForAnalysis/",
                             glue("{placeTitleShort}_{year}_",                        "stacked_",
                                  "{categoryTitleShort}_{leverTitleShort}_",
                                  "Paired_",
                                  "SUMMARY",
                                  "_103",
                                  ".csv"  )))
```

```{r}
(hist_employees_per_company <- 
  df_ProBiz_survey_employees %>% 
    count(c_company_name)%>% 
    ggplot(aes(x = n)) +
    geom_histogram(binwidth = 5, 
                   boundary = 0, 
                   fill = "darkred",
                   color = "black") +
    scale_x_continuous(n.breaks = 15) +
    theme_bw() +
    theme(plot.caption = element_text(hjust = 0)) + # set the left align here
    labs(x = "Number of employees per company",
         y = "Number of companys",
         title = "Histogram of number of employees per company",
         caption = "* Binwidth = 10\n ** Total number of companies is 275"))
```

